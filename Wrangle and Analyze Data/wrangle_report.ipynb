{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When starting with this data set, I wanted to get a look at what exactly I was working with. I started by importing the required libraries and then downloading the main file from the Udemy website as provided. Once I obtained the main twitter archive file I moved on to using the Requests library to grab the image_predictions.tsv file from a cloud server.\n",
    "I went ahead and opened the file in vscode to see what the data looked like. I noticed that the data was separated by a delimiter so to move the information into a data frame I needed to account for this. After creating the new data frame for image_predictions.tsv I displayed the first few rows to check that everything separated into columns correctly. From here I moved on to query the twitter API.\n",
    "\n",
    "Querying the twitter API was not possible, so I chose to download the file from the Udemy course. The reason I chose to download the main file was because the API for Twitter (X) is now very limited unless you pay. I assume when this class was originally created the Twitter API was free to use. I still set up an account and created all the necessary keys and tokens as instructed. I tested the API connection, even though it wouldn’t work, just to make sure that I received something back even if an error. The code for querying the API is left in the notebook and commented out for now.  \n",
    "\n",
    "After figuring out the issue with the twitter API I had all the files I needed for creating my main data set. While looking at the various files, using a programmatic approach, I found some quality issues to clean up. I then merged the individual files into one master file and saved it into the current directory that I’m working out of for my notebook. I moved on to Analyzing and Visualizing the data now that my data was clean and found some fun insights.\n",
    "\n",
    "I learned a lot from this dataset, mainly trying to get an API to function until I found the issue of being a dead end point due to a paywall. But the experience will help me moving forward with the rest of the course work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
